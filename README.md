# activation-steering-vs-prompting
Is activation steering more powerful than prompting at mitigating deception in some current reasoning LLMs?
